{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom_Dataset_TorchText.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNDGL5e3mkMrHG7+nEQIgfx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepshikharbhardwaj/Natural_Language_Processing/blob/main/Custom_Dataset_TorchText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fqUySRvq-3K"
      },
      "source": [
        "#Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HY2xzmNRocgb",
        "outputId": "5fd1b06b-42b6-420c-e8e4-a6a9ab2a89c8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjHxN-2UolCR",
        "outputId": "4f07b714-1325-4842-9290-d7a86f24a0eb"
      },
      "source": [
        "%cd '/content/drive/MyDrive/PyTorch/Torchtext'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/PyTorch/Torchtext\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ytes-VGco95-",
        "outputId": "e5bb72f4-8564-4658-f5fc-270806950aad"
      },
      "source": [
        "!pip install -U torchtext==0.8.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/8a/e09b9b82d4dd676f17aa681003a7533765346744391966dec0d5dba03ee4/torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.8.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2020.12.5)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.9.1\n",
            "    Uninstalling torchtext-0.9.1:\n",
            "      Successfully uninstalled torchtext-0.9.1\n",
            "Successfully installed torchtext-0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT897IKonysv"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import spacy\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yzjMwO1pnvp",
        "outputId": "72aac4f5-0aa9-4d80-8fdb-b62c5d47e9f4"
      },
      "source": [
        "# STEPS:\n",
        "# 1. Specify how preprocessing should be done -> Done by Fields\n",
        "# 2. Use Dataset to load the data -> TabularDataset (JSON/CSV/TSV Files)\n",
        "# 3. Construct an iterator to do batching & padding -> BucketIterator\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenize = lambda x: x.split()\n",
        "# python -m spacy download en\n",
        "#spacy_en = spacy.load(\"en\")\n",
        "\n",
        "#def tokenize(text):\n",
        "#    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "\n",
        "quote = Field(sequential=True, use_vocab=True, tokenize=tokenize, lower=True) #PREPROCESSING\n",
        "score = Field(sequential=False, use_vocab=False)\n",
        "\n",
        "fields = {\"quote\": (\"q\", quote), \"score\": (\"s\", score)} #INPUT DATA Column -> quote and score -> categorize quote as (key q and value quote)\n",
        "\n",
        "train_data, test_data = TabularDataset.splits(path=\"./\", train=\"train.json\", test=\"test.json\", format=\"json\", fields=fields)\n",
        "print('\\n',train_data[0].__dict__.keys(),'\\n')\n",
        "print('\\n',train_data[0].__dict__.values(),'\\n')\n",
        "\n",
        "quote.build_vocab(train_data, max_size=10000, min_freq=1, vectors=\"glove.6B.100d\") #min frequency -> consider that words which have atleast frequency of 1.\n",
        "train_iterator, test_iterator = BucketIterator.splits((train_data, test_data), batch_size=1, device=device)\n",
        "\n",
        "for batch in train_iterator:\n",
        "  print('batch quote \\n',batch.q)\n",
        "  print('batch score \\n', batch.s)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " # train_data, test_data = TabularDataset.splits(path='mydata', train='train.csv', test='test.csv', format='csv', fields=fields)                                    \n",
        " # train_data, test_data = TabularDataset.splits( path='mydata', train='train.tsv', test='test.tsv',format='tsv', fields=fields)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:13: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " dict_keys(['q', 's']) \n",
            "\n",
            "\n",
            " dict_values([['you', 'must', 'own', 'everything', 'in', 'your', 'world.', 'there', 'is', 'no', 'one', 'else', 'to', 'blame.'], 1]) \n",
            "\n",
            "batch quote \n",
            " tensor([[10],\n",
            "        [21],\n",
            "        [ 4],\n",
            "        [ 3],\n",
            "        [ 6],\n",
            "        [11],\n",
            "        [17],\n",
            "        [ 4],\n",
            "        [ 3],\n",
            "        [30],\n",
            "        [28],\n",
            "        [ 5],\n",
            "        [13],\n",
            "        [ 2],\n",
            "        [ 9],\n",
            "        [23]])\n",
            "batch score \n",
            " tensor([1])\n",
            "batch quote \n",
            " tensor([[33],\n",
            "        [19],\n",
            "        [24],\n",
            "        [14],\n",
            "        [15],\n",
            "        [34],\n",
            "        [32],\n",
            "        [31],\n",
            "        [16],\n",
            "        [20],\n",
            "        [22],\n",
            "        [12],\n",
            "        [ 5],\n",
            "        [ 8]])\n",
            "batch score \n",
            " tensor([1])\n",
            "batch quote \n",
            " tensor([[27],\n",
            "        [29],\n",
            "        [ 7],\n",
            "        [26],\n",
            "        [18],\n",
            "        [ 2],\n",
            "        [25]])\n",
            "batch score \n",
            " tensor([0])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUDyBmyUjCDt"
      },
      "source": [
        "#Using Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfxWntBAjDv0",
        "outputId": "4c84390a-f30f-4434-aee7-aebaef99a3e7"
      },
      "source": [
        "# STEPS:\n",
        "# 1. Specify how preprocessing should be done -> Done by Fields\n",
        "# 2. Use Dataset to load the data -> TabularDataset (JSON/CSV/TSV Files)\n",
        "# 3. Construct an iterator to do batching & padding -> BucketIterator\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#tokenize = lambda x: x.split()\n",
        "# python -m spacy download en\n",
        "spacy_en = spacy.load(\"en\")\n",
        "\n",
        "def tokenize(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "\n",
        "quote = Field(sequential=True, use_vocab=True, tokenize=tokenize, lower=True) #PREPROCESSING\n",
        "score = Field(sequential=False, use_vocab=False)\n",
        "\n",
        "fields = {\"quote\": (\"q\", quote), \"score\": (\"s\", score)} #INPUT DATA Column -> quote and score -> categorize quote as (key q and value quote)\n",
        "\n",
        "train_data, test_data = TabularDataset.splits(path=\"./\", train=\"train.json\", test=\"test.json\", format=\"json\", fields=fields)\n",
        "print('\\n',train_data[0].__dict__.keys(),'\\n')\n",
        "print('\\n',train_data[0].__dict__.values(),'\\n')\n",
        "\n",
        "quote.build_vocab(train_data, max_size=10000, min_freq=1, vectors=\"glove.6B.100d\") #min frequency -> consider that words which have atleast frequency of 1.\n",
        "train_iterator, test_iterator = BucketIterator.splits((train_data, test_data), batch_size=1, device=device)\n",
        "\n",
        "for batch in train_iterator:\n",
        "  print('batch quote \\n',batch.q)\n",
        "  print('batch score \\n', batch.s)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:13: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " dict_keys(['q', 's']) \n",
            "\n",
            "\n",
            " dict_values([['you', 'must', 'own', 'everything', 'in', 'your', 'world', '.', 'there', 'is', 'no', 'one', 'else', 'to', 'blame', '.'], 1]) \n",
            "\n",
            "batch quote \n",
            " tensor([[14],\n",
            "        [25],\n",
            "        [ 7],\n",
            "        [ 5],\n",
            "        [10],\n",
            "        [15],\n",
            "        [21],\n",
            "        [ 3],\n",
            "        [ 7],\n",
            "        [ 5],\n",
            "        [32],\n",
            "        [30],\n",
            "        [ 8],\n",
            "        [17],\n",
            "        [ 4],\n",
            "        [13],\n",
            "        [ 6],\n",
            "        [ 2]])\n",
            "batch score \n",
            " tensor([1])\n",
            "batch quote \n",
            " tensor([[35],\n",
            "        [23],\n",
            "        [26],\n",
            "        [18],\n",
            "        [19],\n",
            "        [36],\n",
            "        [34],\n",
            "        [ 2],\n",
            "        [33],\n",
            "        [20],\n",
            "        [24],\n",
            "        [ 6],\n",
            "        [16],\n",
            "        [ 8],\n",
            "        [12],\n",
            "        [ 2]])\n",
            "batch score \n",
            " tensor([1])\n",
            "batch quote \n",
            " tensor([[29],\n",
            "        [31],\n",
            "        [ 3],\n",
            "        [11],\n",
            "        [28],\n",
            "        [22],\n",
            "        [ 4],\n",
            "        [27],\n",
            "        [ 9]])\n",
            "batch score \n",
            " tensor([0])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emkJQU8fzTGx"
      },
      "source": [
        "#Create RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUUGD9ZTq1VT"
      },
      "source": [
        "######### Training a simple LSTM on this toy data of ours #########\n",
        "class RNN_LSTM(nn.Module):\n",
        "    def __init__(self, input_size, embed_size, hidden_size, num_layers):\n",
        "        super(RNN_LSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embed_size)\n",
        "        self.rnn = nn.LSTM(embed_size, hidden_size, num_layers)\n",
        "        self.fc_out = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Set initial hidden and cell states\n",
        "        h0 = torch.zeros(self.num_layers, x.size(1), self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(1), self.hidden_size).to(device)\n",
        "\n",
        "        embedded = self.embedding(x)\n",
        "        outputs, _ = self.rnn(embedded, (h0, c0))\n",
        "        prediction = self.fc_out(outputs[-1, :, :])\n",
        "\n",
        "        return prediction\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpgZPWkgzZMG"
      },
      "source": [
        "#Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khtIWpWFzboF"
      },
      "source": [
        "input_size = len(quote.vocab)\n",
        "hidden_size = 512\n",
        "num_layers = 2\n",
        "embedding_size = 100\n",
        "learning_rate = 0.005\n",
        "num_epochs = 10"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quwrjityzb7G"
      },
      "source": [
        "#Initialize Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI-L4T4mzeKM"
      },
      "source": [
        "model = RNN_LSTM(input_size, embedding_size, hidden_size, num_layers).to(device)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3BRQ4jgzgPN"
      },
      "source": [
        "#Load the pretrained embeddings onto our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ONoGl1_zhcv",
        "outputId": "3310d103-bcfb-401b-f587-88eb95211d89"
      },
      "source": [
        "pretrained_embeddings = quote.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.3398,  0.2094,  0.4635,  ..., -0.2339,  0.4730, -0.0288],\n",
              "        ...,\n",
              "        [ 0.4918,  1.1164,  1.1424,  ..., -0.5088,  0.6256,  0.4392],\n",
              "        [-0.4989,  0.7660,  0.8975,  ..., -0.4118,  0.4054,  0.7850],\n",
              "        [-0.5718,  0.0463,  0.8673,  ..., -0.3566,  0.9293,  0.8995]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWPQa2Vnzh4w"
      },
      "source": [
        "#Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1DqackgzkCa"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztRcfHK1zkM0"
      },
      "source": [
        "#Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGPaJ0egzmZq",
        "outputId": "158e7726-3e1f-412b-da19-579480e0392c"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    losses=[]\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "        # Get data to cuda if possible\n",
        "        data = batch.q.to(device=device)\n",
        "        targets = batch.s.to(device=device)\n",
        "\n",
        "        # forward\n",
        "        scores = model(data)\n",
        "        #print(scores.shape)\n",
        "        loss = criterion(scores.squeeze(1), targets.type_as(scores))\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent\n",
        "        optimizer.step()\n",
        "    print(f\"Loss at epoch {epoch} is { sum(losses)/len(losses) :.5f}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss at epoch 0 is 1.49979\n",
            "Loss at epoch 1 is 1.18254\n",
            "Loss at epoch 2 is 0.85307\n",
            "Loss at epoch 3 is 0.67532\n",
            "Loss at epoch 4 is 0.70580\n",
            "Loss at epoch 5 is 0.69835\n",
            "Loss at epoch 6 is 0.64906\n",
            "Loss at epoch 7 is 0.64026\n",
            "Loss at epoch 8 is 0.64026\n",
            "Loss at epoch 9 is 0.63241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0D2M6OkoR6T"
      },
      "source": [
        "#Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0-5sL0yoTS0",
        "outputId": "89179f6e-eb57-4845-93bb-f7933f986d61"
      },
      "source": [
        "def check_accuracy(loader,model):\n",
        "  if loader.dataset.train:\n",
        "        print('Checking Accuracy on Training Data')\n",
        "  else:\n",
        "        print('Checking Accuracy on Test Data')\n",
        "  num_correct=0\n",
        "  num_samples=0\n",
        "  model.eval()\n",
        "\n",
        "  for batch_idx, batch in enumerate(train_iterator):\n",
        "      x = batch.q.to(device=device)\n",
        "      y = batch.s.to(device=device)\n",
        "      scores=model(x)  \n",
        "      values,predictions =scores.max(1)  #interested in index of the max value\n",
        "      num_correct += (predictions==y).sum()\n",
        "      num_samples += predictions.size(0) \n",
        "\n",
        "  print(f'Got {num_correct}/ {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f} \\n')\n",
        "\n",
        "  model.train()\n",
        "\n",
        "check_accuracy(train_iterator, model)\n",
        "check_accuracy(test_iterator, model)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking Accuracy on Training Data\n",
            "Got 1/ 3 with accuracy 33.33 \n",
            "\n",
            "Checking Accuracy on Training Data\n",
            "Got 1/ 3 with accuracy 33.33 \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}